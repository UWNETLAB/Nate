{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### demonstration of bigram and nlp options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## usage in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nate.import_csv('../data/test.csv', text='content', time='publish_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_tags = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART', 'LAW']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_tags = ['PERSON', 'NORP', 'FAC', 'ORG', 'GPE', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART', 'LAW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = test.svo(sub_tags, obj_tags, to_df=True, bigrams=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>sent_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>svo</th>\n",
       "      <th>subject</th>\n",
       "      <th>sub_type</th>\n",
       "      <th>verb</th>\n",
       "      <th>object</th>\n",
       "      <th>obj_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Even CNN is slamming the Obamas for silence on...</td>\n",
       "      <td>(Even CNN, slamming, the Obamas)</td>\n",
       "      <td>Even CNN</td>\n",
       "      <td>ORG</td>\n",
       "      <td>slamming</td>\n",
       "      <td>the Obamas</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump just dropped a NUKE - truth - bomb : \" T...</td>\n",
       "      <td>(The NFL, suspended, Kaepernick)</td>\n",
       "      <td>The NFL</td>\n",
       "      <td>ORG</td>\n",
       "      <td>suspended</td>\n",
       "      <td>Kaepernick</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>So wait , did the Russians also purchase Hilla...</td>\n",
       "      <td>(the Russians, purchase, Hillary Clinton)</td>\n",
       "      <td>the Russians</td>\n",
       "      <td>NORP</td>\n",
       "      <td>purchase</td>\n",
       "      <td>Hillary Clinton</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>Judge Napolitano calls out Hillary for bogus c...</td>\n",
       "      <td>(Judge Napolitano, calls, Hillary)</td>\n",
       "      <td>Judge Napolitano</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>calls</td>\n",
       "      <td>Hillary</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>Wait ... where were all these women when Bill ...</td>\n",
       "      <td>(Bill Clinton, raped, Juanita Broderick)</td>\n",
       "      <td>Bill Clinton</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>raped</td>\n",
       "      <td>Juanita Broderick</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>13674</td>\n",
       "      <td>0</td>\n",
       "      <td>Tesco is set to dominate the UK again — here '...</td>\n",
       "      <td>(the UK, dominate, Tesco)</td>\n",
       "      <td>the UK</td>\n",
       "      <td>ORG</td>\n",
       "      <td>dominate</td>\n",
       "      <td>Tesco</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>13727</td>\n",
       "      <td>3</td>\n",
       "      <td>You think the NFL gonna give him the SB the same…</td>\n",
       "      <td>(the NFL, give, the SB)</td>\n",
       "      <td>the NFL</td>\n",
       "      <td>ORG</td>\n",
       "      <td>give</td>\n",
       "      <td>the SB</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13823</td>\n",
       "      <td>2</td>\n",
       "      <td>You think the NFL gonna give him the SB the sa...</td>\n",
       "      <td>(the NFL, give, the SB)</td>\n",
       "      <td>the NFL</td>\n",
       "      <td>ORG</td>\n",
       "      <td>give</td>\n",
       "      <td>the SB</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>13860</td>\n",
       "      <td>0</td>\n",
       "      <td>If Hillary Rodham Clinton becomes President - ...</td>\n",
       "      <td>(Hillary Rodham Clinton, becomes, elect Hillar...</td>\n",
       "      <td>Hillary Rodham Clinton</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>becomes</td>\n",
       "      <td>elect Hillary Rodham Clinton</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>13879</td>\n",
       "      <td>1</td>\n",
       "      <td>#Clinton gave Mevs.</td>\n",
       "      <td>(# Clinton, gave, Mevs)</td>\n",
       "      <td># Clinton</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>gave</td>\n",
       "      <td>Mevs</td>\n",
       "      <td>PRODUCT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_id  sent_id                                           sentence  \\\n",
       "0       15        1  Even CNN is slamming the Obamas for silence on...   \n",
       "1       26        1  Trump just dropped a NUKE - truth - bomb : \" T...   \n",
       "2       33        0  So wait , did the Russians also purchase Hilla...   \n",
       "3       36        1  Judge Napolitano calls out Hillary for bogus c...   \n",
       "4       50        0  Wait ... where were all these women when Bill ...   \n",
       "..     ...      ...                                                ...   \n",
       "70   13674        0  Tesco is set to dominate the UK again — here '...   \n",
       "71   13727        3  You think the NFL gonna give him the SB the same…   \n",
       "72   13823        2  You think the NFL gonna give him the SB the sa...   \n",
       "73   13860        0  If Hillary Rodham Clinton becomes President - ...   \n",
       "74   13879        1                                #Clinton gave Mevs.   \n",
       "\n",
       "                                                  svo                 subject  \\\n",
       "0                    (Even CNN, slamming, the Obamas)                Even CNN   \n",
       "1                    (The NFL, suspended, Kaepernick)                 The NFL   \n",
       "2           (the Russians, purchase, Hillary Clinton)            the Russians   \n",
       "3                  (Judge Napolitano, calls, Hillary)        Judge Napolitano   \n",
       "4            (Bill Clinton, raped, Juanita Broderick)            Bill Clinton   \n",
       "..                                                ...                     ...   \n",
       "70                          (the UK, dominate, Tesco)                  the UK   \n",
       "71                            (the NFL, give, the SB)                 the NFL   \n",
       "72                            (the NFL, give, the SB)                 the NFL   \n",
       "73  (Hillary Rodham Clinton, becomes, elect Hillar...  Hillary Rodham Clinton   \n",
       "74                            (# Clinton, gave, Mevs)               # Clinton   \n",
       "\n",
       "   sub_type       verb                        object obj_type  \n",
       "0       ORG   slamming                    the Obamas      ORG  \n",
       "1       ORG  suspended                    Kaepernick      ORG  \n",
       "2      NORP   purchase               Hillary Clinton   PERSON  \n",
       "3    PERSON      calls                       Hillary   PERSON  \n",
       "4    PERSON      raped             Juanita Broderick   PERSON  \n",
       "..      ...        ...                           ...      ...  \n",
       "70      ORG   dominate                         Tesco      GPE  \n",
       "71      ORG       give                        the SB      ORG  \n",
       "72      ORG       give                        the SB      ORG  \n",
       "73   PERSON    becomes  elect Hillary Rodham Clinton   PERSON  \n",
       "74   PERSON       gave                          Mevs  PRODUCT  \n",
       "\n",
       "[75 rows x 9 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.edge_burst_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Offsets:\n",
      "commencing preliminary preparation...\n",
      "finished preliminary preparation in 1 seconds\n",
      "Detecting bigrams...\n",
      "Finished bigram detection.\n",
      "commencing spacy pipeline...\n",
      "finished spacy pipeline in 304 seconds\n",
      "commencing offset generation...\n",
      "finished offset generation in 320 seconds\n",
      "commencing timestamp deduplication...\n",
      "finished timestamp deduplication in 322 seconds\n",
      "Finished Generating Offsets. Returning offset dictionary.\n"
     ]
    }
   ],
   "source": [
    "test2.generate_offset(minimum_offsets=2, bigrams=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = test2.burst_detection(s=2, gamma=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## usage on text within Nate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nate.import_csv('../data/test.csv', text='content', time='publish_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_text = test.list_texts(start=0, end=100, bigrams=True, tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR with NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_nlp_text = test.list_texts(start=0, end=100, bigrams=True, nlp=True, merge_ents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional standard component, currently: lemmatize, lower case, remove stop, remove tokens less than length 3, removes non-ascii text (ie. Russian text)\n",
    "bigram_nlp_text_filtered = test.list_texts(start=0, end=100, bigrams=True, nlp=True, standard_component=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR custom filtered  NOTE: this seems to halt multiprocessing on my machine, I think due to defining and passing the custom component from within the notebook. \n",
    "#The better option might be to allow modifying the imported standard component. But this will likely work fine on Mac and Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_spacy_component():\n",
    "    doc = [token.lemma_.lower() for token in doc if token.is_stop == False and token.is_ascii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_nlp_text_custom = test.list_texts(start=0, end=100, bigrams=True, nlp=True, custom_component=custom_spacy_component)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## manual usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nate.utils.text_helpers import spacy_process, spacy_component, bigram_process\n",
    "from nate.utils.mp_helpers import mp\n",
    "import spacy\n",
    "from spacy.pipeline import merge_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use any list of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_list = your_list_of_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR get list of texts from Nate object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nate.import_csv('../data/test.csv', text='content', time='publish_date')\n",
    "text_list = test.list_texts(start=0, end=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_text = bigram_process(text_list, tokenized = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe(merge_entities)  # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional standard component, currently: lemmatize, lower case, remove stop, remove tokens less than length 3, removes non-ascii text (ie. Russian text)\n",
    "nlp.add_pipe(spacy_component, name=\"standard_component\", last=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR custom filtered  NOTE: this seems to halt multiprocessing on my machine, I think due to defining and passing the custom component from within the notebook. \n",
    "#The better option might be to allow modifying the imported standard component. But this will likely work fine on Mac and Linux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_spacy_component():\n",
    "    doc = [token.lemme_.lower() for token in doc if token.is_stop == False and token.is_ascii]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe(custom_spacy_component, name=\"custom_component\", last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do nlp with multiprocessing function\n",
    "nlp_text = mp(bigram_text, spacy_process, nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sit', 'senator', 'trial', 'corruption', 'peep']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
